# Fedge Version History - CIFAR-10

## Results Summary

| Method | Accuracy | Rounds | Rank | Status |
|--------|----------|--------|------|--------|
| NIID-Bench SCAFFOLD | 69.8% | - | - | üìä Target Baseline |
| **Fedge v10** | **65-68%** | 200 | - | üîÑ Testing (v9 + Data Augmentation) |
| Fedge v9 | 62.9% | 200 | - | ‚úÖ Done (SCAFFOLD fixed, plateau at 62%) |
| Fedge v3 | 60.23% | 100 | 1st | ‚úÖ Done |
| Fedge v2 | 59.16% | 100 | 2nd | ‚úÖ Done |
| Fedge v7 | 58.5% | 200 | - | ‚ùå Failed (collapse) |
| FedProx | 56.29% | 200 | 3rd | ‚úÖ Baseline |
| Fedge v6 | ~56.5% | 200 | 4th | ‚ùå Failed |
| Fedge v4 | ~56% | 200 | 5th | ‚ùå Failed |
| HierFL | 50.58% | 200 | 6th | ‚úÖ Baseline |
| Fedge v1 | 45.07% | 200 | 7th | ‚úÖ Done |
| Fedge v8 | 32.1% | 186 | - | ‚ùå Failed (immediate collapse) |

---

## v10: Data Augmentation - Target 65-68%

### Goal

Add data augmentation to v9 base to break the 62% plateau.

### Approach

v9 SCAFFOLD is stable but plateaued at 62.9%. Per the fallback plan (Scenario B: accuracy < 65%), adding data augmentation is the next step.

### v10 Changes

| Component | v9 | v10 | Expected Gain |
|-----------|-----|-----|---------------|
| AutoAugment | None | CIFAR-10 policy | +2-3% |
| Cutout | None | 16x16 random erasing | +1-2% |
| SCAFFOLD | Enabled (fixed) | Enabled (same) | - |

### v10 Code Changes

**File:** `fedge/task.py` - `_train_transform()` function

```python
# v10: Add AutoAugment + Cutout
from torchvision.transforms import AutoAugment, AutoAugmentPolicy

def _train_transform():
    return Compose([
        RandomCrop(32, padding=4),
        RandomHorizontalFlip(),
        AutoAugment(policy=AutoAugmentPolicy.CIFAR10),  # NEW
        ToTensor(),
        Normalize(_CIFAR10_MEAN, _CIFAR10_STD),
        RandomErasing(p=0.5, scale=(0.02, 0.33)),       # NEW (Cutout equivalent)
    ])
```

### Expected Results

| Phase | Rounds | Expected Accuracy |
|-------|--------|-------------------|
| Early | 1-20 | 25% ‚Üí 45% |
| Mid | 20-50 | 45% ‚Üí 55% |
| Late | 50-100 | 55% ‚Üí 60% |
| Final | 100-200 | 60% ‚Üí **65-68%** |

### If v10 < 65%: Add Weight Decay (v10b)

```toml
weight_decay = 0.0005    # L2 regularization
```

---

## v9: SCAFFOLD Fixed - Result: 62.9%

### Goal

Fix SCAFFOLD implementation bugs that caused v7/v8 collapse. Target: Match NIID-Bench SCAFFOLD results (69.8%).

### Final Result: 62.9% (Below 68% Target)

| Metric | Value |
|--------|-------|
| Final accuracy | **62.9%** |
| Peak accuracy | **63.0%** (round 200) |
| Plateau start | ~round 100 |
| Improvement over v3 | **+2.7%** |

### v9 Training Progression

| Round | Accuracy | Phase |
|-------|----------|-------|
| 1 | 24.9% | Start |
| 20 | 48.5% | Early (on track) |
| 50 | 55.8% | Mid (on track) |
| 100 | 59.6% | Late (slightly behind) |
| 150 | 62.3% | **Plateau forming** |
| 200 | **62.9%** | **Stuck at plateau** |

### Oscillation Pattern Analysis

v9 showed increasing oscillation in later rounds:

| Range | Pattern | Max Dip |
|-------|---------|---------|
| r1-50 | Steady climb | -1.1% |
| r50-100 | Slower climb | -0.6% |
| r100-150 | Oscillating | -0.8% |
| r150-200 | **Stuck** (bouncing 61-63%) | -0.8% |

**Key Insight:** SCAFFOLD corrections are too conservative (0.1 scaling, 0.1 clip) to push past the 62% barrier. The model needs additional regularization (data augmentation) to escape the local minimum.

### Expected vs Actual: Detailed Comparison

| Phase | Rounds | Expected | Actual | Gap | Status |
|-------|--------|----------|--------|-----|--------|
| Early | 1-20 | 25% ‚Üí 45% | 24.9% ‚Üí 48.5% | +3.5% | ‚úÖ **Ahead** |
| Mid | 20-50 | 45% ‚Üí 55% | 48.5% ‚Üí 55.8% | +0.8% | ‚úÖ **On track** |
| Late | 50-100 | 55% ‚Üí 62% | 55.8% ‚Üí 59.6% | **-2.4%** | ‚ö†Ô∏è **Behind** |
| Final | 100-200 | 62% ‚Üí 68% | 59.6% ‚Üí 62.9% | **-5.1%** | ‚ùå **Plateaued** |

**Key Observation:** v9 started strong but fell behind after round 50 and completely plateaued after round 100.

### Gap Analysis: Where Did We Lose 5%?

| Factor | Impact | Evidence | Fix |
|--------|--------|----------|-----|
| **Correction clipping too tight** | -2-3% | SCAFFOLD gains capped at ¬±0.1 per gradient | Try `correction_clip=0.2` |
| **Missing data augmentation** | -3-5% | NIID-Bench likely uses augmentation | ‚úÖ Added in v10 |
| **Scaling factor too conservative** | -1-2% | 0.1 √ó model_diff may underestimate correction | Try `scaling_factor=0.2` |
| **No weight decay** | -0.5-1% | L2 regularization helps generalization | Add `weight_decay=0.0005` |

### Why v9 Underperformed

1. **SCAFFOLD stability achieved** ‚úì (no collapse like v7/v8)
2. **But corrections too weak** - 0.1 scaling factor may be underdoing variance reduction
3. **Plateau at 62%** - Model hit a local minimum that SCAFFOLD alone can't escape
4. **Missing data augmentation** - Standard FL baseline, but augmentation adds +3-5%

### Possible Implementation Issues to Investigate

| Issue | Description | How to Verify |
|-------|-------------|---------------|
| **NIID-Bench setup mismatch** | Their SCAFFOLD config may differ | Check NIID-Bench source code |
| **Control variate initialization** | Starting at zero may not be optimal | Try small random init |
| **Server control update** | Are we updating c_server correctly? | Add debug logging |
| **Gradient magnitude** | Are gradients in expected range (0.001-0.1)? | Log gradient stats |

### Recommendation for v10+

Based on gap analysis, priority order:

1. **v10 (current):** Add data augmentation (+3-5% expected)
2. **v10b (if needed):** Add weight_decay=0.0005 (+0.5-1% expected)
3. **v10c (if still low):** Increase scaling_factor to 0.2 (+1-2% expected)
4. **v10d (experimental):** Loosen correction_clip to 0.2 (risk: oscillation)

### Root Cause Analysis of v7/v8 Collapse

| Bug | Location | Impact |
|-----|----------|--------|
| **20x amplification** | `scaffold_utils.py:82` | `model_diff / (5 * 0.01) = model_diff / 0.05` |
| **No correction clipping** | `scaffold_utils.py:127-128` | Corrections applied unbounded to gradients |
| **Loose control variate clip** | `scaffold_utils.py:86` | clip_value=10.0 way too large |
| **Sudden activation** | `orchestrator.py` | No gradual warmup when SCAFFOLD starts |

### v9 Fixes

| Fix | Old Value | New Value | Effect |
|-----|-----------|-----------|--------|
| **Scaling factor** | `√∑ (K*lr) = √∑0.05` | `√ó 0.1` | Prevents 20x amplification |
| **Correction clipping** | None | `[-0.1, 0.1]` | Bounds gradient corrections |
| **Control variate clip** | 10.0 | **1.0** | Tighter bound on c_i |
| **Warmup scaling** | None | Gradual over 10 rounds | `warmup_factor = round / 10` |

### v9 Configuration

```toml
# pyproject.toml - v9 SCAFFOLD config
scaffold_enabled = true
scaffold_scaling_factor = 0.1    # Replaces 1/(K*lr) division
scaffold_correction_clip = 0.1   # Clip corrections before applying
scaffold_warmup_rounds = 10      # Gradual activation
scaffold_clip_value = 1.0        # Tighter control variate bound
```

### v9 Code Changes

| File | Lines | Change |
|------|-------|--------|
| `fedge/scaffold_utils.py` | 56-57 | Added `scaling_factor=0.1`, `clip_value=1.0` defaults |
| `fedge/scaffold_utils.py` | 83-90 | `scaling_factor * model_diff` instead of division |
| `fedge/scaffold_utils.py` | 117-154 | Added warmup scaling + correction clipping |
| `fedge/task.py` | 530-531, 618-626 | Pass new SCAFFOLD params to train() |
| `orchestrator.py` | 96-105, 248-268 | Read config + pass params |

### Key Formula Changes

**Control Variate Update (update_client_control):**
```python
# OLD (v7/v8) - caused 20x amplification:
new_control = c_i - c_server + model_diff / (local_epochs * lr)

# NEW (v9) - controlled magnitude:
new_control = c_i - c_server + scaling_factor * model_diff  # scaling_factor=0.1
```

**Gradient Correction (apply_scaffold_correction):**
```python
# OLD (v7/v8) - unbounded corrections:
correction = -c_i + c_server
param.grad += correction

# NEW (v9) - clipped + warmup scaled:
warmup_factor = min(1.0, current_round / warmup_rounds)
raw_correction = -c_i + c_server
clipped = torch.clamp(raw_correction, -0.1, 0.1)
param.grad += warmup_factor * clipped
```

### Expected Results

| Phase | Rounds | Expected Accuracy |
|-------|--------|-------------------|
| Early | 1-20 | 25% ‚Üí 45% |
| Mid | 20-50 | 45% ‚Üí 55% |
| Late | 50-100 | 55% ‚Üí 62% |
| Final | 100-200 | 62% ‚Üí **68%+** |

### v9 vs Previous SCAFFOLD Attempts

| Version | SCAFFOLD Config | Result |
|---------|-----------------|--------|
| v7 | Warmup 30 rounds, no fixes | 58.5% (collapsed at r32) |
| v8 | From round 1, no fixes | 32.1% (collapsed at r2) |
| **v9** | Fixed formula + clipping + warmup | **Target: 68-70%** |

### Verification Plan

1. **Smoke test (10 rounds):** No collapse, accuracy > 30%
2. **Short run (50 rounds):** Monotonically increasing, > 50%
3. **Full run (200 rounds):** Target 68%+

### Fallback & Improvement Scenarios

#### If v9 SCAFFOLD Still Collapses (Scenario A)

| Parameter | Try Values | Expected Effect |
|-----------|------------|-----------------|
| `scaling_factor` | 0.05, 0.2, 0.5 | Lower = more conservative |
| `correction_clip` | 0.05, 0.2 | Tighter = more stable |
| `warmup_rounds` | 20, 30 | Longer = smoother activation |

#### If v9 Works But Accuracy < 65% (Scenario B)

**Add Data Augmentation (v10a)** - Expected: +3-5%

| Technique | Expected Gain | File |
|-----------|---------------|------|
| AutoAugment (CIFAR-10) | +2-3% | task.py |
| Cutout (random erasing) | +1-2% | task.py |
| RandAugment | +2-3% | task.py |

#### If v9 Works But Accuracy < 67% (Scenario C)

**Add Regularization (v10b)** - Expected: +1-2%

```toml
weight_decay = 0.0005    # L2 regularization
prox_mu = 0.01           # FedProx (may conflict with SCAFFOLD)
```

#### If SCAFFOLD Fundamentally Broken (Scenario E)

**Fallback to v3 + All Enhancements (v10d)**

```toml
scaffold_enabled = false
weight_decay = 0.0005
prox_mu = 0.01
lr_gamma = 0.99
```

Plus data augmentation ‚Üí Expected: 64-67%

### Decision Tree

```
v9 Smoke Test
‚îú‚îÄ‚îÄ COLLAPSE ‚Üí Tune params (A) or disable SCAFFOLD (E)
‚îî‚îÄ‚îÄ NO COLLAPSE ‚Üí Full run
    ‚îú‚îÄ‚îÄ 68%+ ‚Üí SUCCESS
    ‚îú‚îÄ‚îÄ 65-68% ‚Üí Add augmentation (B)
    ‚îî‚îÄ‚îÄ <65% ‚Üí Add regularization (C) + augmentation
```

### Maximum Theoretical Accuracy

| Configuration | Expected |
|---------------|----------|
| v3 baseline | 60.23% |
| v9 (SCAFFOLD fixed) | 68-70% |
| v9 + Augmentation | 70-72% |
| v9 + Aug + Regularization | 71-73% |
| **LeNet max** | **~75%** |

---

## v8: FAILED - SCAFFOLD from Round 1

### Approach

Fix v7's collapse by starting SCAFFOLD from round 1 instead of after 30-round warmup.

### v8 Results (186 rounds)

| Round | Accuracy | Event |
|-------|----------|-------|
| 1 | 24.2% | Start |
| 3 | **10.4%** | IMMEDIATE COLLAPSE |
| 10 | 12.2% | Stuck |
| 50 | 22.8% | Slow recovery |
| 100 | 27.4% | Still recovering |
| 150 | 30.3% | Climbing |
| 186 | **32.1%** | Final |

**Final: 32.1%** - MUCH WORSE than v7 (58.5%) and v3 (60.23%)

### Why v8 Failed

Starting SCAFFOLD from round 1 caused **immediate collapse** at round 2-3:
1. Control variates initialized to zero made large corrections immediately
2. No stable model state to build corrections from
3. Training destabilized from the very beginning

### Conclusion: SCAFFOLD Implementation Was Buggy

| Version | SCAFFOLD Config | Result |
|---------|-----------------|--------|
| v7 | Warmup 30 rounds | 58.5% (collapsed at r32, recovered) |
| v8 | From round 1 | 32.1% (collapsed at r2, never recovered) |
| v3 | **Disabled** | **60.23%** (best without SCAFFOLD) |
| **v9** | **Fixed bugs** | **Target: 68-70%** |

**v9 Update:** SCAFFOLD collapse was due to implementation bugs (20x amplification, no correction clipping), not fundamental incompatibility. See v9 section above for fixes.

---

## v7: FAILED - SCAFFOLD with 30-Round Warmup

### v7 Results (200 rounds)

| Round | Accuracy | Event |
|-------|----------|-------|
| 1-31 | 25% ‚Üí 52.2% | Good progress |
| 32 | **32.7%** | SCAFFOLD activated ‚Üí COLLAPSE |
| 35 | 19.8% | Bottom |
| 100 | 54.1% | Recovery |
| 150 | 56.9% | Slow climb |
| 200 | **58.5%** | Final |

**Final: 58.5%** (worse than v3's 60.23% at 100 rounds)

### Why v7 Failed

1. **Sudden SCAFFOLD activation**: Control variates initialized at round 31 with model that had already converged partially
2. **20x gradient amplification**: `model_diff / (local_epochs * lr)` = `diff / 0.05`
3. **Model instability**: Large corrections pushed model off its learned distribution

### Lesson Learned

SCAFFOLD warmup causes collapse. Must start SCAFFOLD from round 1 so control variates evolve with the model.

---

## v6: FAILED - Server Isolation + Server-Level SCAFFOLD

### v6 Results (200 rounds)

| Round | Accuracy |
|-------|----------|
| 30 | 48.96% |
| 50 | 51.49% |
| 100 | 54.70% |
| 161 | 56.52% |
| 200 | ~57% |

**Final: ~57%** (worse than v3's 60.23%)

### Why v6 Failed

1. **Immediate isolation**: All 3 servers in separate clusters from round 1
2. **No knowledge sharing during warmup**: Each server got its own model back
3. **Server-level SCAFFOLD couldn't help**: `theta_cluster = theta_server` ‚Üí control variates stayed ~0
4. **Same problem as v4**: Server isolation kills accuracy

### v6 Configuration (for reference)

| Parameter | Value |
|-----------|-------|
| server_isolation | true |
| scaffold_enabled | true |
| scaffold_server_enabled | true |
| prox_mu | 0.0 |

### Lesson Learned

Server isolation doesn't work for this setup. Global averaging (v3 approach) is necessary for good accuracy

---

## v3 Final Results (seed 42, 100 rounds)

| Metric | Value |
|--------|-------|
| Final accuracy | **60.23%** |
| Peak accuracy | **60.93%** (round 98) |
| Plateau start | ~round 70-80 |
| num_clusters | 1 (always) |

### v3 vs Baselines

| Baseline | v3 Improvement |
|----------|----------------|
| FedProx (56.29%) | **+3.94%** |
| HierFL (50.58%) | **+9.65%** |
| Fedge v2 (59.16%) | **+1.07%** |
| Fedge v1 (45.07%) | **+15.16%** |

### v3 Accuracy Progression

| Rounds | Accuracy | Gain per 10 rounds |
|--------|----------|-------------------|
| 1‚Üí10 | 25% ‚Üí 43% | +18% |
| 10‚Üí20 | 43% ‚Üí 49% | +6% |
| 20‚Üí30 | 49% ‚Üí 51.4% | +2.4% |
| 30‚Üí40 | 51.4% ‚Üí 54.9% | +3.5% |
| 40‚Üí50 | 54.9% ‚Üí 55.8% | +0.9% |
| 50‚Üí60 | 55.8% ‚Üí 57.1% | +1.3% |
| 60‚Üí70 | 57.1% ‚Üí 59.4% | +2.3% |
| 70‚Üí80 | 59.4% ‚Üí 58.8% | -0.6% ‚Üê dip |
| 80‚Üí90 | 58.8% ‚Üí 59.0% | +0.2% |
| 90‚Üí100 | 59.0% ‚Üí 60.2% | +1.2% |

### v3 Clustering Analysis

Server similarities at round 100: **0.9985** (all pairs)

**Problem:** Even tau=0.4 can't split servers when similarity > 0.99

---

## Current: v3 200-Round Experiment

Running v3 for 200 rounds to find plateau maximum.

### Expected Results

| Rounds | Expected Accuracy |
|--------|------------------|
| 100 | 60.23% (actual) |
| 150 | ~62% |
| 200 | ~63% (plateau) |

---

## v5: v3 + LR Decay (Current)

### Changes from v3

| Parameter | v3 | v5 | Reason |
|-----------|-----|-----|--------|
| lr_gamma | 1.0 | **0.995** | LR decay for finer convergence |
| Everything else | - | Same as v3 | v4 server isolation hurt accuracy |

### Expected Outcome

LR decay should help with late-round convergence where v3 plateaued.

---

## v4: FAILED - Server Isolation Hurt Accuracy

### What Was Tried

- Each server keeps its own model (no global averaging before clustering)
- Gradient-based clustering
- LR decay (lr_gamma=0.995)

### v4 Results

| Metric | v3 | v4 |
|--------|-----|-----|
| Accuracy | 60.23% | **~56%** |
| num_clusters | 1 | 3 (all separate) |
| Gradient similarities | N/A | 0.003-0.022 |

### Why v4 Failed

1. **Server isolation killed knowledge sharing**: Each server became a local model
2. **Gradient similarities too low**: 0.003-0.022 ‚Üí all 3 servers in separate clusters
3. **No aggregation benefit**: Without knowledge sharing, non-IID hurt more than helped

### Lesson Learned

Clustering for clustering's sake doesn't help. Knowledge sharing through global averaging is critical for accuracy, even if it means servers stay in 1 cluster.

---

## v4 Original Plan (Archived)

### Root Cause Discovery

**Critical Bug Found**: In v1-v3, all servers received the SAME global model before clustering started (rounds 1-29). This prevented servers from diverging based on their non-IID data.

```python
# BUG in orchestrator.py lines 500-502 (v1-v3):
else:
    self.cluster_map = {sid: 0 for sid in server_ids}
    self.cluster_parameters = {0: global_weights}  # ALL servers get SAME model!
```

**Result**: By round 30, server similarities were 0.997+ ‚Üí always 1 cluster ‚Üí clustering never worked.

### v4 Fixes

#### Fix 1: Each Server Keeps Own Model (Critical)

```python
# FIX in orchestrator.py:
else:
    self.cluster_map = {sid: sid for sid in server_ids}
    self.cluster_parameters = {
        sid: weights_list[i] for i, sid in enumerate(server_ids)
    }  # Each server keeps its OWN model
```

**Impact**: Servers now naturally diverge based on non-IID data.

#### Fix 2: Gradient-Based Clustering

Instead of clustering by weight similarity (where models ARE), cluster by gradient direction (where models WANT TO GO).

```python
# New function in cluster_utils.py:
def gradient_based_clustering(server_weights_list, previous_weights_list, tau, round_num):
    # gradient = current_weights - previous_weights
    # similarity = cosine(gradient_i, gradient_j)
    # cluster by similarity threshold
```

**Why it works**: Even if weights converge, gradients reflect local data distribution.

#### Fix 3: LR Decay

```toml
lr_gamma = 0.995  # Decays to ~0.37 by round 200
```

### v4 Configuration Changes

| Parameter | v3 | v4 | Reason |
|-----------|-----|-----|--------|
| Server model sharing | All same | **Each keeps own** | Allow divergence |
| Clustering method | weight | **gradient** | Better for non-IID |
| tau | 0.4 | **0.5** | Adjusted for gradients |
| lr_gamma | 1.0 | **0.995** | Fine convergence |

### v4 Expected Results

| Metric | v3 | v4 Target |
|--------|-----|-----------|
| avg_accuracy (200 rounds) | ~63% | **65-70%** |
| num_clusters | 1 (always) | **2-3** (meaningful) |
| Server similarities | 0.997+ | **0.3-0.8** |

### v4 Key Files Modified

| File | Change |
|------|--------|
| `orchestrator.py:500-506` | Each server keeps own model |
| `orchestrator.py:476-488` | Gradient-based clustering support |
| `orchestrator.py:438` | Track previous_server_weights |
| `fedge/cluster_utils.py` | New `gradient_based_clustering()` function |
| `pyproject.toml` | method="gradient", lr_gamma=0.995 |

---

## v2 Final Results (seed 42, 100 rounds)

| Metric | Value |
|--------|-------|
| Final accuracy | 59.16% |
| Peak accuracy | 59.68% (round 98) |
| Plateau start | ~round 70-80 |
| num_clusters | 1 (always) |

### v2 vs Baselines

| Baseline | v2 Improvement |
|----------|----------------|
| FedProx (56.29%) | **+2.87%** |
| HierFL (50.58%) | **+8.58%** |
| Fedge v1 (45.07%) | **+14.09%** |

### v2 Accuracy Progression

| Rounds | Accuracy | Gain per 10 rounds |
|--------|----------|-------------------|
| 1‚Üí10 | 25% ‚Üí 42% | +17% |
| 10‚Üí20 | 42% ‚Üí 49% | +7% |
| 20‚Üí30 | 49% ‚Üí 51.5% | +2.5% |
| 30‚Üí40 | 51.5% ‚Üí 54.4% | +2.9% |
| 40‚Üí50 | 54.4% ‚Üí 55.1% | +0.7% |
| 50‚Üí60 | 55.1% ‚Üí 56.2% | +1.1% |
| 60‚Üí70 | 56.2% ‚Üí 58.1% | +1.9% |
| 70‚Üí80 | 58.1% ‚Üí 58.3% | +0.2% ‚Üê plateau |
| 80‚Üí90 | 58.3% ‚Üí 58.5% | +0.2% |
| 90‚Üí100 | 58.5% ‚Üí 59.2% | +0.7% |

---

## v1 ‚Üí v2 Changes

### Configuration Changes

| Parameter | v1 | v2 | Reason |
|-----------|-----|-----|--------|
| `prox_mu` | 0.001 | **0.01** | Match FedProx regularization strength |
| `momentum` | 0.0 | **0.9** | Standard SGD momentum for faster convergence |
| `start_round` | 1 | **30** | Let models differentiate before clustering |

### What Worked in v2

| Change | Impact |
|--------|--------|
| momentum=0.9 | Faster, smoother convergence |
| prox_mu=0.01 | Reduced client drift |

### What Didn't Work in v2

| Issue | Observation |
|-------|-------------|
| Clustering | Still 1 cluster always (tau=0.7 too high) |
| start_round=30 | No effect (similarities still > 0.7) |

---

## v3 Attempt: SCAFFOLD Failed

### What We Tried

| Parameter | v2 | v3 (attempted) |
|-----------|-----|----------------|
| `scaffold_enabled` | false | **true** |
| `tau` | 0.7 | **0.4** |
| `label_smoothing` | 0.1 | **0.0** |

### SCAFFOLD Failure (seed 42)

```
Round 6:  38.97%  ‚Üê SCAFFOLD activates after warmup (5 rounds)
Round 7:  21.08%  ‚Üê CATASTROPHIC COLLAPSE
Round 8:  18.20%
...
Round 44: 19.48%  ‚Üê stuck near random
```

### Root Cause Analysis

1. **SCAFFOLD warmup too short** - Only 5 rounds, not enough for stable control variates
2. **Control variate explosion** - Division by `(local_epochs * lr)` = 0.05 amplifies by 20x
3. **Conflict with FedProx** - Both methods try to correct drift differently
4. **No gradient clipping on SCAFFOLD corrections** - Unbounded corrections

### Lesson Learned

SCAFFOLD needs careful tuning:
- Longer warmup (30+ rounds)
- Scaled-down corrections
- Possibly incompatible with FedProx

---

## v3 Revised Plan (No SCAFFOLD)

### Configuration Changes

| Parameter | v2 | v3 | Reason |
|-----------|-----|-----|--------|
| `scaffold_enabled` | false | **false** | SCAFFOLD caused collapse |
| `tau` | 0.7 | **0.4** | Force multiple clusters |
| `label_smoothing` | 0.1 | **0.0** | Match baselines |

### Expected Outcome

| Metric | v2 | v3 Target |
|--------|-----|-----------|
| avg_accuracy | 59.16% | **60-63%** |
| num_clusters | 1 | >1 after round 30 |

### Expected Gains

| Change | Expected Gain |
|--------|---------------|
| Lower tau (0.4) | +1-2% (if clusters form) |
| Remove label smoothing | +1-2% |
| **Total** | **+2-4%** ‚Üí **61-63%** |

---

## v2 Issues & Plateau Analysis

### Issue A: Clustering Never Activated
- `num_clusters = 1` for all 100 rounds
- tau=0.7 too high (all server similarities > 0.7)
- No server specialization happening

### Issue B: Label Smoothing Mismatch
- v2 uses `label_smoothing=0.1`
- FedProx baseline uses `label_smoothing=0.0`
- Cost: ~1-2% accuracy

### Issue C: Plateau at ~59%
- Gains dropped to +0.2% per 10 rounds after round 70
- Possible causes:
  1. LeNet capacity ceiling (~62-65% theoretical max)
  2. Fixed learning rate (no decay)
  3. Clustering not helping (single cluster)
  4. Non-IID drift accumulation

---

## Brainstorming: Breaking the Plateau

### Ideas Within Sacred Constraints

| Idea | Expected Gain | Risk | Priority |
|------|---------------|------|----------|
| **Lower tau (0.4‚Üí0.3)** | +1-3% | May over-fragment | High |
| **LR decay (cosine)** | +1-2% | Slower early | Medium |
| **Gradient clipping adjustment** | +0.5-1% | May destabilize | Low |
| **Warmup LR schedule** | +0.5-1% | Complexity | Low |

### Ideas Requiring Sacred Parameter Changes

| Idea | Expected Gain | Constraint Violation |
|------|---------------|---------------------|
| ResNet-18 | +10-15% | Model (LeNet) |
| More local epochs | +2-3% | local_epochs=5 |
| Lower alpha_server | +2-4% | alpha_server=0.5 |

### Clustering Improvements

| Idea | Description |
|------|-------------|
| **Gradient-based clustering** | Cluster by gradient direction, not weight similarity |
| **Adaptive tau** | Start high (0.7), decay to 0.3 over rounds |
| **Per-layer clustering** | Cluster based on last FC layer only (already doing this) |
| **Cluster-specific LR** | Different learning rates per cluster |

### Novel Approaches

| Idea | Description | Complexity |
|------|-------------|------------|
| **FedDyn** | Dynamic regularizer instead of FedProx | High |
| **MOON** | Contrastive learning between local/global | High |
| **Personalization layers** | Freeze backbone, personalize last layer per cluster | Medium |

---

## Sacred Parameters (Cannot Change)

| Parameter | Value | Reason |
|-----------|-------|--------|
| `lr_init` | 0.01 | NIID-Bench standard |
| `local_epochs` | 5 | Match baselines |
| `batch_size` | 64 | Match baselines |
| `num_servers` | 3 | Match HierFL |
| `clients_per_server` | [5, 5, 5] | Match HierFL |
| `alpha_server` | 0.5 | Non-IID standard |
| `alpha_client` | 1000.0 | IID within server |
| Model | LeNet | Match all baselines |

---

## File Locations

- Config: `/mnt/d/learn/CIFAR-10/Fedge-Simulation/pyproject.toml`
- Task: `/mnt/d/learn/CIFAR-10/Fedge-Simulation/fedge/task.py`
- Orchestrator: `/mnt/d/learn/CIFAR-10/Fedge-Simulation/orchestrator.py`

## Git History

- **v10: (current)** - Data augmentation to break 62% plateau
  - New: AutoAugment with CIFAR-10 policy
  - New: RandomErasing (Cutout equivalent) p=0.5
  - SCAFFOLD: Unchanged from v9 (stable, no collapse)
  - Target: 65-68%
  - Files: `fedge/task.py` (_train_transform)
- v9: 62.9% - SCAFFOLD bug fixes (stable but plateaued)
  - Fix: Replace `√∑(K*lr)` with `√ó scaling_factor` (prevents 20x amplification)
  - Fix: Add correction clipping `[-0.1, 0.1]` before applying to gradients
  - Fix: Tighten control variate clip from 10.0 to 1.0
  - New: Gradual warmup scaling over 10 rounds
  - Result: +2.7% over v3, but below 68% target
  - Files: `fedge/scaffold_utils.py`, `fedge/task.py`, `orchestrator.py`, `pyproject.toml`
- v8: 32.1% - SCAFFOLD from round 1 (failed - immediate collapse)
- v7: 58.5% - SCAFFOLD with 30-round warmup (failed - collapse at r32)
- v3: 60.23% (100 rounds) - tau=0.4, no label smoothing, SCAFFOLD disabled
- v2: commit `b524d42` - 59.16%
- v1: commit `32a5d29` and earlier - 45.07%
